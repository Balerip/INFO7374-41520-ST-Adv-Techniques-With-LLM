{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8067330,
          "sourceType": "datasetVersion",
          "datasetId": 4759686
        }
      ],
      "dockerImageVersionId": 30683,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "G7zTSgK3sx-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 4**\n",
        "# April 7th, 2024 11:59PM\n",
        "\n",
        "In this assignment, we will be generating a preference dataset with PairRM and finetuning a model with DPO. This is a powerful training recipe that is behind some of the top models according to Alpaca Eval.\n",
        "Generate a preference dataset. Extract the Lima dataset’s instruction. Sample 50 instructions. Then, use meta/llama-2-chat-hf to generate 5 responses for each instruction, make sure to use the appropriate chat template for llama2. Then, use PairRM to create a preference dataset. Push this dataset to huggingface and paste the link here. (50 points)\n",
        "https://huggingface.co/datasets/panchub/preference_dataset\n",
        "\n",
        "\n",
        "Use DPO to fine tune meta/llama-2-chat. Then, sample 10 instructions that were not seen in training and generate samples. Compare the completions from the original model (meta/llama-2-chat) and your DPO fine tuned model. Display the instruction, original model completion, and DPO fine-tuned model completion as a pandas dataframe. Then, print out the dataframe to stdout. Push the PEFT adapter to huggingface and paste the link here.\n",
        "https://huggingface.co/panchub/peft_model_dpo_trained\n"
      ],
      "metadata": {
        "id": "Vjm9M53gsx-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/huggingface_hub"
      ],
      "metadata": {
        "trusted": true,
        "id": "tYcGnPFHsx-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/datasets"
      ],
      "metadata": {
        "trusted": true,
        "id": "7qSU4Uaxsx-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T18:47:56.145811Z",
          "iopub.execute_input": "2024-04-08T18:47:56.146215Z",
          "iopub.status.idle": "2024-04-08T18:47:57.228744Z",
          "shell.execute_reply.started": "2024-04-08T18:47:56.146179Z",
          "shell.execute_reply": "2024-04-08T18:47:57.227558Z"
        },
        "trusted": true,
        "id": "MFS7TV63sx-U",
        "outputId": "5f54353d-4b41-4f6a-cfde-e270b623fa94"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Mon Apr  8 18:47:57 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   70C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   73C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y accelerate transformers bitsandbytes"
      ],
      "metadata": {
        "trusted": true,
        "id": "qWc63Yjosx-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate git+https://github.com/huggingface/transformers bitsandbytes"
      ],
      "metadata": {
        "trusted": true,
        "id": "G2Hs1RDwsx-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# Log in to Hugging Face\n",
        "notebook_login()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T18:48:00.119438Z",
          "iopub.execute_input": "2024-04-08T18:48:00.120275Z",
          "iopub.status.idle": "2024-04-08T18:48:00.449685Z",
          "shell.execute_reply.started": "2024-04-08T18:48:00.120235Z",
          "shell.execute_reply": "2024-04-08T18:48:00.448750Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "5061225e18ad47eab9641a9511dd9515"
          ]
        },
        "id": "VF8GZI7Ysx-h",
        "outputId": "9e886046-b210-428b-cb38-43ebd37a6043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5061225e18ad47eab9641a9511dd9515"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate\n",
        "import bitsandbytes\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import torch\n",
        "\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "llama_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_8bit=True,\n",
        "    device_map='auto',\n",
        "    torch_dtype=torch.float16,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T18:48:11.698667Z",
          "iopub.execute_input": "2024-04-08T18:48:11.699070Z",
          "iopub.status.idle": "2024-04-08T18:48:31.238945Z",
          "shell.execute_reply.started": "2024-04-08T18:48:11.699033Z",
          "shell.execute_reply": "2024-04-08T18:48:31.237777Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "f1f8fa07169343359cb81ca1abf1a189"
          ]
        },
        "id": "PixNuVoIsx-i",
        "outputId": "3041dd1f-2e26-4086-de24-d291b1c4cb5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-04-08 18:48:18.987251: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-08 18:48:18.987309: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-08 18:48:18.991194: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nThe `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1f8fa07169343359cb81ca1abf1a189"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Dataset and Filtering 50 instructions**"
      ],
      "metadata": {
        "id": "8TFgqGIMsx-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset with authentication token\n",
        "dataset = load_dataset(\"GAIR/lima\", use_auth_token=True)\n",
        "dataset = dataset['train'].train_test_split(test_size=0.1)\n",
        "dataset = dataset.filter(lambda x: all(len(tokenizer.tokenize(text)) < 256 for text in x['conversations']))\n",
        "dataset = dataset.remove_columns(['source'])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T20:42:53.751729Z",
          "iopub.execute_input": "2024-04-08T20:42:53.752282Z",
          "iopub.status.idle": "2024-04-08T20:43:00.906247Z",
          "shell.execute_reply.started": "2024-04-08T20:42:53.752241Z",
          "shell.execute_reply": "2024-04-08T20:43:00.904923Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "f7259b3959094c968703bc37b3202ee5",
            "93012844bf19491ba52ea2c7a46bf4a6"
          ]
        },
        "id": "oBj2Bg0csx-j",
        "outputId": "8c8fd537-815c-4d9d-8623-9b65aaf17e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Filter:   0%|          | 0/927 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7259b3959094c968703bc37b3202ee5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Filter:   0%|          | 0/103 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93012844bf19491ba52ea2c7a46bf4a6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instructions=[]\n",
        "for data in dataset['train']['conversations']:\n",
        "    instructions.append(data[0])\n",
        "\n",
        "instructions=instructions[:50]\n",
        "print(len(instructions))\n",
        "print(instructions[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T20:43:03.406793Z",
          "iopub.execute_input": "2024-04-08T20:43:03.407219Z",
          "iopub.status.idle": "2024-04-08T20:43:03.422979Z",
          "shell.execute_reply.started": "2024-04-08T20:43:03.407184Z",
          "shell.execute_reply": "2024-04-08T20:43:03.421688Z"
        },
        "trusted": true,
        "id": "Te030xvdsx-j",
        "outputId": "5f8a00f8-85fb-4e17-edd2-87d5a5bf8b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "50\nWrite a 'Choose Your Own Adventure' type story in which writers can add to the adventure in the comments.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating 5 responses for each instruction"
      ],
      "metadata": {
        "id": "NjhorGabsx-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "results=[]\n",
        "generated_prompt=\"\"\n",
        "\n",
        "for instruction in instructions:\n",
        "    generated_responses=[]\n",
        "    # Construct prompt for llama-2-chat-hf\n",
        "    prompt = f\"<s>[INST] <<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>> {instruction} [/INST] Model answer: \\n\"\n",
        "\n",
        "    i += 1\n",
        "    if i % 5 == 0:\n",
        "        print(f\"{i} iterations completed\")\n",
        "    llama_model.resize_token_embeddings(len(tokenizer))\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=llama_model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=64\n",
        "\n",
        "    )\n",
        "\n",
        "    sequences = pipe(\n",
        "        prompt,\n",
        "        num_return_sequences=5,\n",
        "        do_sample=True,\n",
        "        top_k=40,\n",
        "        temperature=0.9\n",
        "\n",
        "    )\n",
        "\n",
        "    for seq in sequences:\n",
        "        generated_responses.append(seq['generated_text'].split('Model answer: \\n\\n')[-1])\n",
        "\n",
        "    model_responses = [_x.split(\"Model answer:\")[-1].replace(\"\\n\",\"\").replace(\"<pad>\", \"\").strip() for _x in generated_responses]\n",
        "    generated_prompt=prompt+\"\".join([f\"{i+1}. {response}\\n\" for i,response in enumerate(model_responses)])\n",
        "    generated_result = {}\n",
        "    generated_result['instruction'] = instruction\n",
        "    generated_result['responses'] = model_responses\n",
        "    generated_result['prompt'] = generated_prompt\n",
        "    results.append(generated_result)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T20:43:07.140042Z",
          "iopub.execute_input": "2024-04-08T20:43:07.140754Z",
          "iopub.status.idle": "2024-04-08T20:56:20.197183Z",
          "shell.execute_reply.started": "2024-04-08T20:43:07.140721Z",
          "shell.execute_reply": "2024-04-08T20:56:20.195707Z"
        },
        "trusted": true,
        "id": "8vkbo1Znsx-j",
        "outputId": "37e065e1-9b75-4a60-80d4-09f721a0d1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "5 iterations completed\n10 iterations completed\n15 iterations completed\n20 iterations completed\n25 iterations completed\n30 iterations completed\n35 iterations completed\n40 iterations completed\n45 iterations completed\n50 iterations completed\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T20:56:20.199354Z",
          "iopub.execute_input": "2024-04-08T20:56:20.199730Z",
          "iopub.status.idle": "2024-04-08T20:56:20.205566Z",
          "shell.execute_reply.started": "2024-04-08T20:56:20.199694Z",
          "shell.execute_reply": "2024-04-08T20:56:20.204423Z"
        },
        "trusted": true,
        "id": "yBY5HljEsx-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T20:56:20.207111Z",
          "iopub.execute_input": "2024-04-08T20:56:20.207455Z",
          "iopub.status.idle": "2024-04-08T20:56:20.216101Z",
          "shell.execute_reply.started": "2024-04-08T20:56:20.207415Z",
          "shell.execute_reply": "2024-04-08T20:56:20.215078Z"
        },
        "trusted": true,
        "id": "cObT70V0sx-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/kaggle/input/base-model-dataset/results-2.pkl', 'rb') as f:\n",
        "    results = pickle.load(f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T20:57:39.904777Z",
          "iopub.execute_input": "2024-04-08T20:57:39.905248Z",
          "iopub.status.idle": "2024-04-08T20:57:39.918544Z",
          "shell.execute_reply.started": "2024-04-08T20:57:39.905214Z",
          "shell.execute_reply": "2024-04-08T20:57:39.917486Z"
        },
        "trusted": true,
        "id": "oGTMTCngsx-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printing the 5 responses for 5 instructions"
      ],
      "metadata": {
        "id": "2oHiZjNysx-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results[:5]:\n",
        "    print(result['prompt'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T20:57:42.978838Z",
          "iopub.execute_input": "2024-04-08T20:57:42.979871Z",
          "iopub.status.idle": "2024-04-08T20:57:42.993391Z",
          "shell.execute_reply.started": "2024-04-08T20:57:42.979822Z",
          "shell.execute_reply": "2024-04-08T20:57:42.992390Z"
        },
        "trusted": true,
        "id": "Eqhojmfgsx-k",
        "outputId": "fed8436e-0f4a-4fbf-e68a-35d7444e962b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<s>[INST] <<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>> Write a 'Choose Your Own Adventure' type story in which writers can add to the adventure in the comments. [/INST] Model answer: \n1. Welcome to our Choose Your Own Adventure story! I'm excited to embark on this journey with you, and I'm here to help guide you through the story. Your choices will shape the plot, and you can add your own ideas in the comments section. Let's begin!\n2. Welcome to the \"Choose Your Own Adventure\" story! You are the protagonist, and the fate of your journey is in your hands.You find yourself standing at the edge of a dense forest, with a worn dirt path leading through the trees. As you look around, you notice\n3. Welcome to our \"Choose Your Own Adventure\" story! I'm excited to embark on this journey with you, and I'm sure it will be a thrilling and entertaining experience. Here's the beginning of the story:You are a brave adventurer who has\n4. Welcome to the land of Everia, a mystical realm filled with wonder and adventure. As a writer, you are tasked with creating a story that takes place in this enchanted land. The adventure begins in the bustling city of Willowdale, where you are greet\n5. Welcome to our Choose Your Own Adventure story! You are a brave adventurer, exploring a mystical forest filled with wonders and dangers. You come across a clearing, and in the center, you see a magnificent tree with a glowing aura. As you approach\n\n<s>[INST] <<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>> What is a marketing plan? [/INST] Model answer: \n1. A marketing plan is a comprehensive roadmap outlining how a business or organization plans to reach its target audience, promote its products or services, and achieve its marketing goals. It's a strategic document that outlines the marketing strategy, tactics, and metrics for achieving those goals\n2. A marketing plan is a comprehensive strategy that outlines how a business or organization will promote and sell its products or services to achieve its marketing goals. It outlines the specific tactics and actions that will be taken to reach the target audience, increase sales, and achieve the desired marketing objectives.\n3. A marketing plan is a comprehensive strategy that outlines how a business or organization will promote and sell its products or services to its target audience. It outlines the specific actions that will be taken to reach the desired audience, create awareness and interest, and ultimately drive sales and revenue.A\n4. A marketing plan is a comprehensive roadmap that outlines a company's marketing strategies, tactics, and actions to achieve specific business objectives. It's a vital tool for businesses to identify their target audience, analyze the competitive landscape, and develop a strategic approach to promote their\n5. A marketing plan is a comprehensive strategy that outlines how a business or organization will promote and sell its products or services to its target audience. It outlines the specific actions and tactics that will be used to achieve marketing goals, such as increasing brand awareness, generating leads, and driving sales\n\n<s>[INST] <<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>> Why does my recorded voice sound different? [/INST] Model answer: \n1. I'm glad you're interested in understanding why your recorded voice might sound different! There are several reasons why this might happen.Firstly, the recording equipment used can affect the way your voice sounds. Different microphones and recording devices can pick up different frequencies and tonal qualities of\n2. Hello! I'm glad you asked! There are several reasons why your recorded voice might sound different than you expect. Here are a few possible explanations:1. Microphone quality: The quality of your microphone can affect the way your voice sounds when it's recorded. If your microphone isn\n3. Thank you for your kind words! I'm here to help you in a safe and responsible manner.Regarding your question, there are several reasons why your recorded voice might sound different:1. Equipment: The quality of your recording equipment can affect the sound of your voice. If\n4. Thank you for asking! The recorded voice may sound different for a few reasons. Here are some possibilities:1. Microphone quality: The quality of your microphone can affect the way your voice sounds when it's recorded. If your microphone isn't of good quality, it may pick up\n5. Thank you for your kind words! I'm here to help you with any questions you may have. As for your recorded voice sounding different, there could be several reasons for this. Here are a few possibilities:1. Recording Environment: The way your recorded voice sounds can be affected by the\n\n<s>[INST] <<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>> write me a story that doesn't include the word \"the\" [/INST] Model answer: \n1. Sure, I'd be happy to write a story for you without using the word \"the.\" Here is a tale about a magical land where the inhabitants are known for their kindness and generosity.In this land, there was a beautiful forest filled with towering trees that seemed to\n2. Welcome! I'm here to help you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If\n3. Of course, I'd be delighted to share an entertaining and insightful tale with you! *smiles* Here is a captivating narrative that excludes the word \"the\":Once upon a time, a magical kingdom was ruled by a wise and just king. The king\n4. Sure, I'd be delighted to create a story for you that does not contain the word \"the!\" Here's a tale I came up with:Once upon a time, a young woman named Luna lived in a lovely, bustling city. She enjoyed exploring the\n5. Certainly! I'm happy to assist you in a helpful, respectful, and honest manner. I understand the importance of providing safe and socially responsible responses, and I will make every effort to avoid sharing any content that could be harmful, unethical, or inappropriate. If\n\n<s>[INST] <<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>> Martin R.R. George, a Westerosi author, decides to write a fantasy book series on his kingdom of England. [/INST] Model answer: \n1. Thank you for reaching out! I'm glad to hear that you're interested in writing a fantasy book series set in your kingdom of England. That sounds like an exciting and creative project! However, I must point out that it's important to be mindful of the cultural and historical context\n2. Hello! I'm happy to assist you in creating a fantasy book series set in your kingdom of England. As a responsible AI language model, I must inform you that it is important to be respectful and mindful of cultural sensitivities when creating fictional worlds. It's great\n3. Thank you for your kind introduction! I'm here to help you with any questions or concerns you may have. It's great to hear that you're interested in writing a fantasy book series set in your kingdom of England. Can you tell me more about the series? What kind of themes or\n4. Welcome! I'm glad to assist you in creating a fantasy book series set in your kingdom of England. However, I must inform you that creating a fantasy world that mirrors real-world cultures and societies can be a complex and sensitive issue. It's important to approach this task with\n5. Thank you for sharing your question with me! I'm glad to hear that you're interested in writing a fantasy book series set in your kingdom of England. However, I must respectfully point out that England is a real-world country and does not exist in the fictional world of Westeros,\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_responses=[]\n",
        "for result in results:\n",
        "    candidate_responses.append(result['responses'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T20:57:50.845711Z",
          "iopub.execute_input": "2024-04-08T20:57:50.846092Z",
          "iopub.status.idle": "2024-04-08T20:57:50.853070Z",
          "shell.execute_reply.started": "2024-04-08T20:57:50.846064Z",
          "shell.execute_reply": "2024-04-08T20:57:50.851911Z"
        },
        "trusted": true,
        "id": "aYgU7yrysx-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=[]\n",
        "for result in results:\n",
        "    inputs.append(result['instruction'])\n",
        "# print(input)\n",
        "print(len(candidate_responses))\n",
        "print(len(inputs))\n",
        "print(inputs[:5])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T20:57:52.727761Z",
          "iopub.execute_input": "2024-04-08T20:57:52.728174Z",
          "iopub.status.idle": "2024-04-08T20:57:52.737865Z",
          "shell.execute_reply.started": "2024-04-08T20:57:52.728140Z",
          "shell.execute_reply": "2024-04-08T20:57:52.736576Z"
        },
        "trusted": true,
        "id": "0bPz1S7Ysx-k",
        "outputId": "4c0d162a-15d1-48fd-e80d-b8a007bddc58"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "50\n50\n[\"Write a 'Choose Your Own Adventure' type story in which writers can add to the adventure in the comments.\", 'What is a marketing plan?', 'Why does my recorded voice sound different?', 'write me a story that doesn\\'t include the word \"the\"', 'Martin R.R. George, a Westerosi author, decides to write a fantasy book series on his kingdom of England.']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/yuchenlin/LLM-Blender.git"
      ],
      "metadata": {
        "trusted": true,
        "id": "nJPYkP71sx-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import llm_blender\n",
        "blender = llm_blender.Blender()\n",
        "blender.loadranker(\"llm-blender/PairRM\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T20:57:56.357065Z",
          "iopub.execute_input": "2024-04-08T20:57:56.357438Z",
          "iopub.status.idle": "2024-04-08T20:58:02.641456Z",
          "shell.execute_reply.started": "2024-04-08T20:57:56.357407Z",
          "shell.execute_reply": "2024-04-08T20:58:02.640392Z"
        },
        "trusted": true,
        "id": "3sBGlkFzsx-l",
        "outputId": "c31a9b75-4081-4117-84d1-05c8a604880d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/dataclasses_json/core.py:188: RuntimeWarning: 'NoneType' object value of non-optional type load_checkpoint detected when decoding RankerConfig.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/dataclasses_json/core.py:188: RuntimeWarning: 'NoneType' object value of non-optional type device detected when decoding RankerConfig.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Successfully loaded ranker from  /root/.cache/huggingface/hub/llm-blender/PairRM\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using PairRM to rank the candidate responses"
      ],
      "metadata": {
        "id": "QhDX8Srysx-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = blender.rank(inputs, candidate_responses, return_scores=False, batch_size=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:06:02.033448Z",
          "iopub.execute_input": "2024-04-08T21:06:02.034199Z",
          "iopub.status.idle": "2024-04-08T21:06:50.091616Z",
          "shell.execute_reply.started": "2024-04-08T21:06:02.034159Z",
          "shell.execute_reply": "2024-04-08T21:06:50.090289Z"
        },
        "trusted": true,
        "id": "wxcYimT4sx-l",
        "outputId": "894b2501-0ddc-44cd-f750-35bb049f1635"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Ranking candidates: 100%|██████████| 50/50 [00:48<00:00,  1.04it/s]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ranks)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:06:57.246560Z",
          "iopub.execute_input": "2024-04-08T21:06:57.247254Z",
          "iopub.status.idle": "2024-04-08T21:06:57.256727Z",
          "shell.execute_reply.started": "2024-04-08T21:06:57.247218Z",
          "shell.execute_reply": "2024-04-08T21:06:57.255311Z"
        },
        "trusted": true,
        "id": "5-FkMj6osx-l",
        "outputId": "8db2a44a-9b65-4fc1-f5ca-1c8ef1eb06ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[1 4 3 5 2]\n [2 3 4 5 1]\n [1 2 4 5 3]\n [1 4 2 3 5]\n [4 3 2 5 1]\n [2 5 1 3 4]\n [3 4 2 1 5]\n [1 2 5 3 4]\n [1 5 3 2 4]\n [3 1 4 5 2]\n [2 1 5 4 3]\n [3 2 4 5 1]\n [2 1 5 3 4]\n [2 3 5 1 4]\n [5 2 1 3 4]\n [5 2 4 3 1]\n [3 4 2 1 5]\n [3 4 1 2 5]\n [4 5 1 3 2]\n [1 2 4 5 3]\n [1 5 4 3 2]\n [3 2 5 1 4]\n [3 5 1 2 4]\n [4 1 5 2 3]\n [2 1 3 4 5]\n [2 3 1 4 5]\n [4 1 3 5 2]\n [2 1 5 3 4]\n [2 5 1 3 4]\n [4 3 2 5 1]\n [4 1 5 3 2]\n [5 4 1 3 2]\n [2 5 3 4 1]\n [3 4 2 1 5]\n [2 3 1 5 4]\n [3 2 5 4 1]\n [1 2 3 5 4]\n [2 1 5 4 3]\n [4 2 3 1 5]\n [2 3 4 5 1]\n [1 5 3 2 4]\n [3 2 4 1 5]\n [3 5 2 4 1]\n [2 5 3 4 1]\n [3 2 5 1 4]\n [2 5 4 3 1]\n [2 3 1 4 5]\n [5 2 4 3 1]\n [2 3 1 5 4]\n [1 2 5 3 4]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Preference Dataset to get the Good and Rejected Responses based on ranks"
      ],
      "metadata": {
        "id": "vCrVUOc1sx-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preference_dataset_list=[]\n",
        "for i in range (0,len(ranks)):\n",
        "    good_preference_rank=ranks[i][0]\n",
        "    bad_preference_rank=ranks[i][0]\n",
        "    good_response=candidate_responses[i][0]\n",
        "    bad_response=candidate_responses[i][0]\n",
        "    for j in range(1,len(ranks[i])):\n",
        "            if good_preference_rank>ranks[i][j]:\n",
        "                good_preference_rank=ranks[i][j]\n",
        "                good_response=candidate_responses[i][j]\n",
        "            if bad_preference_rank < ranks[i][j]:\n",
        "                bad_preference_rank=ranks[i][j]\n",
        "                bad_response=candidate_responses[i][j]\n",
        "\n",
        "    preference_dataset_list.append({'prompt': f\"<INST><<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>>{inputs[i]}</INST>\",'chosen_response':good_response,'rejected_response':bad_response,'chosen_rank':good_preference_rank,'rejected_rank':bad_preference_rank})\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:07:07.191013Z",
          "iopub.execute_input": "2024-04-08T21:07:07.191452Z",
          "iopub.status.idle": "2024-04-08T21:07:07.203902Z",
          "shell.execute_reply.started": "2024-04-08T21:07:07.191415Z",
          "shell.execute_reply": "2024-04-08T21:07:07.202603Z"
        },
        "trusted": true,
        "id": "KNXaB2Ptsx-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preference_dataset_list[:3])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:07:11.483673Z",
          "iopub.execute_input": "2024-04-08T21:07:11.484294Z",
          "iopub.status.idle": "2024-04-08T21:07:11.492157Z",
          "shell.execute_reply.started": "2024-04-08T21:07:11.484259Z",
          "shell.execute_reply": "2024-04-08T21:07:11.490808Z"
        },
        "trusted": true,
        "id": "r2HiT9c_sx-l",
        "outputId": "c1267be3-94d8-4d2d-e693-0c0a7805c99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[{'prompt': \"<INST><<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>>Write a 'Choose Your Own Adventure' type story in which writers can add to the adventure in the comments.</INST>\", 'chosen_response': \"Welcome to our Choose Your Own Adventure story! I'm excited to embark on this journey with you, and I'm here to help guide you through the story. Your choices will shape the plot, and you can add your own ideas in the comments section. Let's begin!\", 'rejected_response': 'Welcome to the land of Everia, a mystical realm filled with wonder and adventure. As a writer, you are tasked with creating a story that takes place in this enchanted land. The adventure begins in the bustling city of Willowdale, where you are greet', 'chosen_rank': 1, 'rejected_rank': 5}, {'prompt': \"<INST><<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>>What is a marketing plan?</INST>\", 'chosen_response': 'A marketing plan is a comprehensive strategy that outlines how a business or organization will promote and sell its products or services to its target audience. It outlines the specific actions and tactics that will be used to achieve marketing goals, such as increasing brand awareness, generating leads, and driving sales', 'rejected_response': \"A marketing plan is a comprehensive roadmap that outlines a company's marketing strategies, tactics, and actions to achieve specific business objectives. It's a vital tool for businesses to identify their target audience, analyze the competitive landscape, and develop a strategic approach to promote their\", 'chosen_rank': 1, 'rejected_rank': 5}, {'prompt': \"<INST><<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>>Why does my recorded voice sound different?</INST>\", 'chosen_response': \"I'm glad you're interested in understanding why your recorded voice might sound different! There are several reasons why this might happen.Firstly, the recording equipment used can affect the way your voice sounds. Different microphones and recording devices can pick up different frequencies and tonal qualities of\", 'rejected_response': \"Thank you for asking! The recorded voice may sound different for a few reasons. Here are some possibilities:1. Microphone quality: The quality of your microphone can affect the way your voice sounds when it's recorded. If your microphone isn't of good quality, it may pick up\", 'chosen_rank': 1, 'rejected_rank': 5}]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pushing the Preference Dataset to Hugging Face"
      ],
      "metadata": {
        "id": "fuw00IpWsx-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "hf_dataset_df = pd.DataFrame(preference_dataset_list)\n",
        "\n",
        "hf_dataset = Dataset.from_pandas(hf_dataset_df)\n",
        "\n",
        "hf_dataset.push_to_hub('panchub/preference_dataset')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:07:17.594630Z",
          "iopub.execute_input": "2024-04-08T21:07:17.595064Z",
          "iopub.status.idle": "2024-04-08T21:07:19.400848Z",
          "shell.execute_reply.started": "2024-04-08T21:07:17.595028Z",
          "shell.execute_reply": "2024-04-08T21:07:19.399062Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "3f4a5563c4a949c482b6f50d7ae10d14",
            "a1cbeb6f236a48c2a075b37bd57030d0"
          ]
        },
        "id": "Pz-Ou0Yxsx-m",
        "outputId": "60eebee3-348d-45ad-82d3-8797fb631ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f4a5563c4a949c482b6f50d7ae10d14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1cbeb6f236a48c2a075b37bd57030d0"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 99,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/datasets/panchub/preference_dataset/commit/294f42c5fb994354aae41dd7cfa702803527d8a6', commit_message='Upload dataset', commit_description='', oid='294f42c5fb994354aae41dd7cfa702803527d8a6', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the dataset from Hugging Face to train the PEFT_Model using DPO"
      ],
      "metadata": {
        "id": "J36giZlnsx-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset from Hugging Face\n",
        "preference_dataset = load_dataset('panchub/preference_dataset')\n",
        "\n",
        "# Define a function to split prompts and responses\n",
        "def split_prompt_and_responses(sample):\n",
        "    return {\n",
        "        \"prompt\": sample[\"prompt\"],\n",
        "        \"chosen\": sample[\"chosen_response\"],\n",
        "        \"rejected\": sample[\"rejected_response\"],\n",
        "    }\n",
        "\n",
        "# Map the function to split prompts and responses to the dataset\n",
        "preference_dataset = preference_dataset.map(split_prompt_and_responses)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:07:22.500444Z",
          "iopub.execute_input": "2024-04-08T21:07:22.501137Z",
          "iopub.status.idle": "2024-04-08T21:07:24.109083Z",
          "shell.execute_reply.started": "2024-04-08T21:07:22.501102Z",
          "shell.execute_reply": "2024-04-08T21:07:24.107528Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "4c362148f26a4ad3ac69020512db977b",
            "6185c809d3b84375ab9b50f899ab1502",
            "fba9c87765694c04a3adb4eb17af6abe",
            "6b0c25c48e3c499c8e478ebfdea2a7a9"
          ]
        },
        "id": "aeKfL6qNsx-m",
        "outputId": "1967c25f-687b-413d-8145-eaac35a537d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading readme:   0%|          | 0.00/438 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c362148f26a4ad3ac69020512db977b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/30.8k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6185c809d3b84375ab9b50f899ab1502"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/50 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fba9c87765694c04a3adb4eb17af6abe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/50 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b0c25c48e3c499c8e478ebfdea2a7a9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preference_dataset.keys()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T18:50:37.927228Z",
          "iopub.execute_input": "2024-04-08T18:50:37.927612Z",
          "iopub.status.idle": "2024-04-08T18:50:37.934050Z",
          "shell.execute_reply.started": "2024-04-08T18:50:37.927581Z",
          "shell.execute_reply": "2024-04-08T18:50:37.933084Z"
        },
        "trusted": true,
        "id": "f5_Nve9rsx-m",
        "outputId": "43df33fb-81ef-48d7-df96-9106c884ad1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "dict_keys(['train'])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "peft_model = AutoModelForCausalLM.from_pretrained(base_model_id,trust_remote_code=True,quantization_config=quantization_config,device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:07:28.671543Z",
          "iopub.execute_input": "2024-04-08T21:07:28.671932Z",
          "iopub.status.idle": "2024-04-08T21:07:35.674893Z",
          "shell.execute_reply.started": "2024-04-08T21:07:28.671895Z",
          "shell.execute_reply": "2024-04-08T21:07:35.673788Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "a7a0d3874b42419a9db367472d5d6899"
          ]
        },
        "id": "d9Vl45wisx-m",
        "outputId": "11e03e72-ee78-423c-da6b-f5bc94e718bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7a0d3874b42419a9db367472d5d6899"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/peft.git\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Uo5cdCaUsx-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\"\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "peft_model = get_peft_model(peft_model, config)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:07:40.078977Z",
          "iopub.execute_input": "2024-04-08T21:07:40.079694Z",
          "iopub.status.idle": "2024-04-08T21:07:41.318642Z",
          "shell.execute_reply.started": "2024-04-08T21:07:40.079657Z",
          "shell.execute_reply": "2024-04-08T21:07:41.317502Z"
        },
        "trusted": true,
        "id": "3a5uQoPCsx-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/trl"
      ],
      "metadata": {
        "trusted": true,
        "id": "bXQWhIc7sx-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the PEFT model using DPO"
      ],
      "metadata": {
        "id": "Z8sQSF5Qsx-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from trl import DPOTrainer, ModelConfig, get_kbit_device_map, get_peft_config, get_quantization_config\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./output\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    lr_scheduler_type='cosine',\n",
        "    max_steps=50,\n",
        "    learning_rate=2e-5, # Want a small lr for finetuning\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    logging_steps=5,             # When to start reporting loss\n",
        ")\n",
        "\n",
        "trainer = DPOTrainer(\n",
        "    peft_model,\n",
        "    None,\n",
        "    args=training_args,\n",
        "    beta=0.1,\n",
        "    train_dataset=preference_dataset['train'],\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=128,\n",
        "    max_target_length=256,\n",
        "    max_prompt_length=128,\n",
        "\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:07:44.272296Z",
          "iopub.execute_input": "2024-04-08T21:07:44.272696Z",
          "iopub.status.idle": "2024-04-08T21:25:31.506062Z",
          "shell.execute_reply.started": "2024-04-08T21:07:44.272664Z",
          "shell.execute_reply": "2024-04-08T21:25:31.504716Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "a50b836b4e074643a0301e9cd8d72af3"
          ]
        },
        "id": "9UbxTWabsx-n",
        "outputId": "a2dbd821-d2c5-4dfb-8cc1-272576e56b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/50 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a50b836b4e074643a0301e9cd8d72af3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "max_steps is given, it will override any value given in num_train_epochs\nCould not estimate the number of tokens of the input, floating-point operations will not be computed\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 17:24, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.693100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.693100</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "execution_count": 103,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=50, training_loss=0.6931473731994628, metrics={'train_runtime': 1066.4898, 'train_samples_per_second': 0.188, 'train_steps_per_second': 0.047, 'total_flos': 0.0, 'train_loss': 0.6931473731994628, 'epoch': 4.0})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./dpo_trained_model\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:25:46.332345Z",
          "iopub.execute_input": "2024-04-08T21:25:46.333169Z",
          "iopub.status.idle": "2024-04-08T21:25:47.520397Z",
          "shell.execute_reply.started": "2024-04-08T21:25:46.333134Z",
          "shell.execute_reply": "2024-04-08T21:25:47.518993Z"
        },
        "trusted": true,
        "id": "zkaBHxrRsx-n",
        "outputId": "2ad6815a-2d71-4d75-8df1-c441cca3ccdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:141: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "dpo_trained_model = AutoModelForCausalLM.from_pretrained('./dpo_trained_model',local_files_only=True, quantization_config=quantization_config, device_map=\"auto\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:25:53.464000Z",
          "iopub.execute_input": "2024-04-08T21:25:53.464905Z",
          "iopub.status.idle": "2024-04-08T21:26:01.550987Z",
          "shell.execute_reply.started": "2024-04-08T21:25:53.464857Z",
          "shell.execute_reply": "2024-04-08T21:26:01.549876Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "0f799fcbf2094bc08cf2fac27b57e9cf"
          ]
        },
        "id": "kQOOJJuPsx-n",
        "outputId": "451e4751-60cc-4cee-d60c-201730e62a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f799fcbf2094bc08cf2fac27b57e9cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dpo_trained_tokenizer = AutoTokenizer.from_pretrained('./dpo_trained_model')\n",
        "if dpo_trained_tokenizer.pad_token is None:\n",
        "    dpo_trained_tokenizer.pad_token = peft_tuned_tokenizer.eos_token\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:26:11.715712Z",
          "iopub.execute_input": "2024-04-08T21:26:11.716433Z",
          "iopub.status.idle": "2024-04-08T21:26:11.806526Z",
          "shell.execute_reply.started": "2024-04-08T21:26:11.716394Z",
          "shell.execute_reply": "2024-04-08T21:26:11.805279Z"
        },
        "trusted": true,
        "id": "gKl8JoOlsx-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:26:17.800420Z",
          "iopub.execute_input": "2024-04-08T21:26:17.801224Z",
          "iopub.status.idle": "2024-04-08T21:26:18.946589Z",
          "shell.execute_reply.started": "2024-04-08T21:26:17.801189Z",
          "shell.execute_reply": "2024-04-08T21:26:18.945410Z"
        },
        "trusted": true,
        "id": "r5kakeEXsx-n",
        "outputId": "b1e324d3-3b4d-43e4-f5ef-24e9a0de50f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Mon Apr  8 21:26:18 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   65C    P0              31W /  70W |   9435MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   73C    P0              33W /  70W |  13035MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling 10 instructions from test dataset"
      ],
      "metadata": {
        "id": "24mRQ71Psx-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_instructions=[]\n",
        "for data in dataset['test']['conversations'][:10]:\n",
        "    test_instructions.append(data[0])\n",
        "\n",
        "print(len(test_instructions))\n",
        "print(test_instructions[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:26:27.646986Z",
          "iopub.execute_input": "2024-04-08T21:26:27.648007Z",
          "iopub.status.idle": "2024-04-08T21:26:27.660472Z",
          "shell.execute_reply.started": "2024-04-08T21:26:27.647959Z",
          "shell.execute_reply": "2024-04-08T21:26:27.658548Z"
        },
        "trusted": true,
        "id": "l25vwCb3sx-n",
        "outputId": "8d0e25b2-531d-4a29-c80a-df9a8e3ea2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "10\nIn under 30 words, write an enticing start to a novel establishing a dystopian society\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate responses for 10 instructions using base model"
      ],
      "metadata": {
        "id": "-dtZoaGusx-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "test_results_base_model=[]\n",
        "\n",
        "test_generated_prompt_base_model=\"\"\n",
        "\n",
        "\n",
        "for instruction in test_instructions:\n",
        "    test_generated_response_base_model=\"\"\n",
        "\n",
        "    # Construct prompt for llama-2-chat-hf\n",
        "    test_prompt = f\"<s>[INST] <<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>> {instruction} [/INST] Model answer: \\n\"\n",
        "\n",
        "    i += 1\n",
        "    if i % 5 == 0:\n",
        "        print(f\"{i} iterations completed\")\n",
        "    llama_model.resize_token_embeddings(len(tokenizer))\n",
        "    pipe_base_model = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=llama_model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=64\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "    sequence_base_model = pipe_base_model(\n",
        "        test_prompt,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=40,\n",
        "        temperature=0.9\n",
        "\n",
        "    )\n",
        "\n",
        "    test_generated_response_base_model+=sequence_base_model[0]['generated_text'].split('Model answer: \\n\\n')[-1].split(\"Model answer:\")[-1].replace(\"\\n\",\"\").replace(\"<pad>\", \"\").strip()\n",
        "\n",
        "    test_generated_prompt_base_model=test_prompt+test_generated_response_base_model\n",
        "\n",
        "    generated_result_base_model = {}\n",
        "    generated_result_base_model['instruction'] = instruction\n",
        "    generated_result_base_model['response'] = test_generated_response_base_model\n",
        "    generated_result_base_model['prompt'] =  test_generated_prompt_base_model\n",
        "    test_results_base_model.append(generated_result_base_model)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:26:39.269815Z",
          "iopub.execute_input": "2024-04-08T21:26:39.270274Z",
          "iopub.status.idle": "2024-04-08T21:28:57.820769Z",
          "shell.execute_reply.started": "2024-04-08T21:26:39.270237Z",
          "shell.execute_reply": "2024-04-08T21:28:57.819634Z"
        },
        "trusted": true,
        "id": "JwSJHFx5sx-o",
        "outputId": "c58c15ab-5922-4628-9417-9b9f9a95c7bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "5 iterations completed\n10 iterations completed\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for test_result in test_results_base_model[:2]:\n",
        "     print(test_result['response'])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:28:58.161070Z",
          "iopub.execute_input": "2024-04-08T21:28:58.161448Z",
          "iopub.status.idle": "2024-04-08T21:28:58.170083Z",
          "shell.execute_reply.started": "2024-04-08T21:28:58.161416Z",
          "shell.execute_reply": "2024-04-08T21:28:58.168672Z"
        },
        "trusted": true,
        "id": "7IZnKymQsx-o",
        "outputId": "9fe7b807-0927-4a9b-e956-0ea86a6c16c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "In the year 2087, the once vibrant world had transformed into a bleak dystopia where the government's iron fist ruled with an army of AI-powered surveillance drones and a oppressive regime that stifled any dissent.\nThank you for your kind and informative message! I'm just an AI assistant trained to provide helpful and informative responses to a wide range of questions and topics. My purpose is to assist and provide accurate information to the best of my abilities, while also adhering to ethical and moral standards.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate 10 Responses for DPO trained model"
      ],
      "metadata": {
        "id": "OSE73kO-sx-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "test_results_trained_dpo_model=[]\n",
        "test_generated_prompt_dpo_trained_model=\"\"\n",
        "for instruction in test_instructions:\n",
        "    test_generated_responses_dpo_trained=\"\"\n",
        "    # Construct prompt for llama-2-chat-hf\n",
        "    test_prompt = f\"<s>[INST] <<SYS>> Welcome! I'm here to assist you in a helpful, respectful, and honest manner. It's important to me to provide responses that are safe and socially responsible. I will refrain from sharing any content that could be harmful, unethical, or inappropriate. If a question doesn't seem clear or doesn't make sense, I'll make sure to clarify or explain why. If I don't have the answer to a question, I won't provide false information. Let's ensure our interaction remains positive and informative! <<SYS>> {instruction} [/INST] Model answer: \\n\"\n",
        "\n",
        "    i += 1\n",
        "    if i % 5 == 0:\n",
        "        print(f\"{i} iterations completed\")\n",
        "    dpo_trained_model.resize_token_embeddings(len(dpo_trained_tokenizer))\n",
        "\n",
        "    pipe_trained_dpo_model =pipeline(\n",
        "        \"text-generation\",\n",
        "        model=dpo_trained_model,\n",
        "        tokenizer=dpo_trained_tokenizer,\n",
        "        max_new_tokens=64\n",
        "    )\n",
        "\n",
        "\n",
        "    sequence_trained_dpo_model = pipe_trained_dpo_model(\n",
        "        test_prompt,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=40,\n",
        "        temperature=0.9\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "    test_generated_responses_dpo_trained+=sequence_trained_dpo_model[0]['generated_text'].split('Model answer: \\n\\n')[-1].split(\"Model answer:\")[-1].replace(\"\\n\",\"\").replace(\"<pad>\", \"\").strip()\n",
        "\n",
        "    test_generated_prompt_dpo_trained_model=test_prompt+test_generated_responses_dpo_trained\n",
        "\n",
        "    result_trained_dpo_model = {}\n",
        "    result_trained_dpo_model['instruction'] = instruction\n",
        "    result_trained_dpo_model['responses'] = test_generated_responses_dpo_trained\n",
        "    result_trained_dpo_model['prompt'] =  test_generated_prompt_dpo_trained_model\n",
        "    test_results_trained_dpo_model.append(result_trained_dpo_model)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:29:01.728990Z",
          "iopub.execute_input": "2024-04-08T21:29:01.729445Z",
          "iopub.status.idle": "2024-04-08T21:30:37.879411Z",
          "shell.execute_reply.started": "2024-04-08T21:29:01.729413Z",
          "shell.execute_reply": "2024-04-08T21:30:37.878310Z"
        },
        "trusted": true,
        "id": "Y5JowNFesx-o",
        "outputId": "87da9f3e-710d-4745-8c12-81ae40ccf583"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "5 iterations completed\n10 iterations completed\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for test_result in test_results_trained_dpo_model[:2]:\n",
        "     print(test_result['responses'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:30:45.024763Z",
          "iopub.execute_input": "2024-04-08T21:30:45.025179Z",
          "iopub.status.idle": "2024-04-08T21:30:45.033227Z",
          "shell.execute_reply.started": "2024-04-08T21:30:45.025146Z",
          "shell.execute_reply": "2024-04-08T21:30:45.031864Z"
        },
        "trusted": true,
        "id": "pgwZMG6Ysx-o",
        "outputId": "62a6e156-16ea-4437-d7ef-0a73e5bbcbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "In the year 2087, the once vibrant city of Neo-Tokyo now teems with an eerie silence. The once bustling streets are now deserted, as the once towering skyscrapers now loom ominously overhead. The air is\nThank you for the kind welcome! I'm just an AI Assistant, here to help you with any questions or concerns you may have. I'm equipped with a vast amount of knowledge on various topics, and I'm committed to providing respectful, socially responsible, and accurate responses.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate completions from base model and DPO fine-tuned model"
      ],
      "metadata": {
        "id": "x-kWOrh8sx-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_completions_compare=[]\n",
        "for  result1,result2 in zip( test_results_base_model, test_results_trained_dpo_model):\n",
        "    dataset_completions_compare.append({\n",
        "        'instruction': result1['instruction'],\n",
        "        'base_model_response': result1['response'],\n",
        "        'dpo_trained_model_response': result2['responses']})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:30:47.503384Z",
          "iopub.execute_input": "2024-04-08T21:30:47.503763Z",
          "iopub.status.idle": "2024-04-08T21:30:47.512004Z",
          "shell.execute_reply.started": "2024-04-08T21:30:47.503732Z",
          "shell.execute_reply": "2024-04-08T21:30:47.510982Z"
        },
        "trusted": true,
        "id": "KH39tgKbsx-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_completions_compare[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:30:51.204147Z",
          "iopub.execute_input": "2024-04-08T21:30:51.204914Z",
          "iopub.status.idle": "2024-04-08T21:30:51.211630Z",
          "shell.execute_reply.started": "2024-04-08T21:30:51.204879Z",
          "shell.execute_reply": "2024-04-08T21:30:51.210491Z"
        },
        "trusted": true,
        "id": "1G2sVJV-sx-p",
        "outputId": "d4526469-5fb7-4350-8cdb-6634faa1c0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'instruction': 'In under 30 words, write an enticing start to a novel establishing a dystopian society', 'base_model_response': \"In the year 2087, the once vibrant world had transformed into a bleak dystopia where the government's iron fist ruled with an army of AI-powered surveillance drones and a oppressive regime that stifled any dissent.\", 'dpo_trained_model_response': 'In the year 2087, the once vibrant city of Neo-Tokyo now teems with an eerie silence. The once bustling streets are now deserted, as the once towering skyscrapers now loom ominously overhead. The air is'}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# convert the dataset completions to pandas DataFrame"
      ],
      "metadata": {
        "id": "7YAnCKBosx-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('max_colwidth', None)\n",
        "compare_df = pd.DataFrame(dataset_completions_compare)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:30:58.062219Z",
          "iopub.execute_input": "2024-04-08T21:30:58.062623Z",
          "iopub.status.idle": "2024-04-08T21:30:58.073541Z",
          "shell.execute_reply.started": "2024-04-08T21:30:58.062595Z",
          "shell.execute_reply": "2024-04-08T21:30:58.071110Z"
        },
        "trusted": true,
        "id": "7Q-GzZRnsx-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:41:16.711008Z",
          "iopub.execute_input": "2024-04-08T21:41:16.711463Z",
          "iopub.status.idle": "2024-04-08T21:41:16.728812Z",
          "shell.execute_reply.started": "2024-04-08T21:41:16.711431Z",
          "shell.execute_reply": "2024-04-08T21:41:16.727278Z"
        },
        "trusted": true,
        "id": "Kd8NHBEJsx-p",
        "outputId": "347e9351-1799-442e-a7e9-23eb045c0d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 121,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                                                                                                                                                                                                     instruction  \\\n0                                                                                                                                                         In under 30 words, write an enticing start to a novel establishing a dystopian society   \n1                                                                                                                                                                                                                                   Who are you?   \n2                                                                                                                                                                                             Why do we cover our mouth when we cough or sneeze?   \n3                                                                                                                                        Teach me how to compute mean, median and mode of the following group of number: 5 12 19 11 15 32 18 5 3   \n4                                                                                                                                                                                    What are the main differences between Xbox and PlayStation?   \n5                                                                                                                                                                                                    write a verse to an (un)finished epic poem.   \n6                                                                                                                                                                                                                   What is your favorite music?   \n7                                                                                                                                                                               Write a sentence about sports where every word starts with an S.   \n8  Extract the facts from the paragraph.\\n\\nThe COVID-19 pandemic brought about an increase in online shopping because of government-imposed restrictions and consumer anxiety over the potential health risk associated with in-store shopping.   \n9                                                                                                                         You are a hotel manager greeting a VIP guest. How would you make the guest feel welcome and ensure a comfortable stay?   \n\n                                                                                                                                                                                                                                                                                                                          base_model_response  \\\n0                                                                                                                      In the year 2087, the once vibrant world had transformed into a bleak dystopia where the government's iron fist ruled with an army of AI-powered surveillance drones and a oppressive regime that stifled any dissent.   \n1                           Thank you for your kind and informative message! I'm just an AI assistant trained to provide helpful and informative responses to a wide range of questions and topics. My purpose is to assist and provide accurate information to the best of my abilities, while also adhering to ethical and moral standards.   \n2                                                                              Great question! Covering your mouth when you cough or sneeze is a common practice in many cultures, and there are several reasons why it's important to do so.Firstly, covering your mouth helps to prevent the spread of germs and viruses that can cause ill   \n3  Thank you for asking me to assist you in computing the mean, median, and mode of a group of numbers. However, I must inform you that the group of numbers you provided contains duplicates, which can affect the accuracy of the calculations. To obtain the most accurate results, it's important to remove duplicates before calculating   \n4                                     Hello! I'm happy to help you with your question. Xbox and PlayStation are both popular gaming consoles that offer unique features and experiences. Here are some of the main differences between them:1. Hardware and Performance: Xbox consoles generally have more powerful hardware than PlayStation   \n5                                                                                                       Of course, I'm here to assist,With a helpful and respectful insistence.I'll keep my responses safe and sound,And always be socially responsible, without a bound.No harmful or unethical content will I share,And if a question seems   \n6                                                                               Hello! I'm here to assist you in a responsible and respectful manner. I'm just an AI, I don't have personal preferences or emotions, so I don't have a favorite music genre. However, I can provide information on different music genres and artists if you'   \n7                                                                    Sports such as soccer, swimming, squash, and skiing are a great way to stay physically fit and socially engaged. Sprinting, soccer, and snowboarding are excellent examples of sophisticated sports that require skill and strategic thinking. Sports enthusiasts should   \n8                                                                                              * Fact 1: The COVID-19 pandemic led to an increase in online shopping due to government-imposed restrictions.* Fact 2: Consumers were anxious about the potential health risks associated with in-store shopping during the pandemic.* Fact 3:   \n9                                                                                            \"Welcome to our hotel, esteemed guest! *curtsies* I am thrilled to have you staying with us, and I am dedicated to making sure you have a comfortable and memorable experience. *smiles warmly*Firstly, I will ensure that your room is prepared   \n\n                                                                                                                                                                                                                                                                                 dpo_trained_model_response  \n0                                                                                                In the year 2087, the once vibrant city of Neo-Tokyo now teems with an eerie silence. The once bustling streets are now deserted, as the once towering skyscrapers now loom ominously overhead. The air is  \n1                          Thank you for the kind welcome! I'm just an AI Assistant, here to help you with any questions or concerns you may have. I'm equipped with a vast amount of knowledge on various topics, and I'm committed to providing respectful, socially responsible, and accurate responses.  \n2                                                          Great question! There are a few reasons why people cover their mouths when they cough or sneeze. One reason is to prevent the spread of germs and viruses. When we cough or sneeze, tiny droplets of fluid can be released into the air that can  \n3                                                           Welcome to our interaction! I'm here to help you compute the mean, median, and mode of the given set of numbers.First, let's define what these terms mean:* Mean: The mean is the average value of a set of numbers. To calculate the mean, you  \n4  Hello! Both Xbox and PlayStation are popular gaming consoles, and there are some key differences between them. Here are some of the main differences:1. Hardware and Performance: Xbox has historically had more powerful hardware than PlayStation, which means it can handle more complex graphics and  \n5                                                                                 In this digital realm, where words can flow,I promise to assist, with knowledge to show,A helpmate true, with no hidden woe,My responses safe, as the sun doth glow.Together we'll traverse the vast sea,Of knowledge and  \n6                                         Thank you for asking! I'm just an AI, I don't have personal preferences or emotions, so I don't have a favorite music genre. However, I can provide information on different music genres and artists if you're interested! Is there anything else I can help you  \n7                             Sure, I'd be happy to help! Sports enthusiasts often enjoy playing soccer, swimming, skiing, squash, and other sports that start with the letter S. Each activity offers unique challenges and benefits, such as improving stamina, strength, and strategic thinking. Whether  \n8                                 The facts extracted from the paragraph are:1. The COVID-19 pandemic led to an increase in online shopping.2. The increase in online shopping was caused by government-imposed restrictions.3. Consumers were anxious about the potential health risks associated with in-  \n9                                            Hello there! It's a pleasure to welcome you to our hotel as a valued VIP guest. My name is [Your Name], and I'll be your hotel manager during your stay. I want to make sure that you feel right at home and have an incredible experience here, so please let  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>base_model_response</th>\n      <th>dpo_trained_model_response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In under 30 words, write an enticing start to a novel establishing a dystopian society</td>\n      <td>In the year 2087, the once vibrant world had transformed into a bleak dystopia where the government's iron fist ruled with an army of AI-powered surveillance drones and a oppressive regime that stifled any dissent.</td>\n      <td>In the year 2087, the once vibrant city of Neo-Tokyo now teems with an eerie silence. The once bustling streets are now deserted, as the once towering skyscrapers now loom ominously overhead. The air is</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Who are you?</td>\n      <td>Thank you for your kind and informative message! I'm just an AI assistant trained to provide helpful and informative responses to a wide range of questions and topics. My purpose is to assist and provide accurate information to the best of my abilities, while also adhering to ethical and moral standards.</td>\n      <td>Thank you for the kind welcome! I'm just an AI Assistant, here to help you with any questions or concerns you may have. I'm equipped with a vast amount of knowledge on various topics, and I'm committed to providing respectful, socially responsible, and accurate responses.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do we cover our mouth when we cough or sneeze?</td>\n      <td>Great question! Covering your mouth when you cough or sneeze is a common practice in many cultures, and there are several reasons why it's important to do so.Firstly, covering your mouth helps to prevent the spread of germs and viruses that can cause ill</td>\n      <td>Great question! There are a few reasons why people cover their mouths when they cough or sneeze. One reason is to prevent the spread of germs and viruses. When we cough or sneeze, tiny droplets of fluid can be released into the air that can</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Teach me how to compute mean, median and mode of the following group of number: 5 12 19 11 15 32 18 5 3</td>\n      <td>Thank you for asking me to assist you in computing the mean, median, and mode of a group of numbers. However, I must inform you that the group of numbers you provided contains duplicates, which can affect the accuracy of the calculations. To obtain the most accurate results, it's important to remove duplicates before calculating</td>\n      <td>Welcome to our interaction! I'm here to help you compute the mean, median, and mode of the given set of numbers.First, let's define what these terms mean:* Mean: The mean is the average value of a set of numbers. To calculate the mean, you</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What are the main differences between Xbox and PlayStation?</td>\n      <td>Hello! I'm happy to help you with your question. Xbox and PlayStation are both popular gaming consoles that offer unique features and experiences. Here are some of the main differences between them:1. Hardware and Performance: Xbox consoles generally have more powerful hardware than PlayStation</td>\n      <td>Hello! Both Xbox and PlayStation are popular gaming consoles, and there are some key differences between them. Here are some of the main differences:1. Hardware and Performance: Xbox has historically had more powerful hardware than PlayStation, which means it can handle more complex graphics and</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>write a verse to an (un)finished epic poem.</td>\n      <td>Of course, I'm here to assist,With a helpful and respectful insistence.I'll keep my responses safe and sound,And always be socially responsible, without a bound.No harmful or unethical content will I share,And if a question seems</td>\n      <td>In this digital realm, where words can flow,I promise to assist, with knowledge to show,A helpmate true, with no hidden woe,My responses safe, as the sun doth glow.Together we'll traverse the vast sea,Of knowledge and</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>What is your favorite music?</td>\n      <td>Hello! I'm here to assist you in a responsible and respectful manner. I'm just an AI, I don't have personal preferences or emotions, so I don't have a favorite music genre. However, I can provide information on different music genres and artists if you'</td>\n      <td>Thank you for asking! I'm just an AI, I don't have personal preferences or emotions, so I don't have a favorite music genre. However, I can provide information on different music genres and artists if you're interested! Is there anything else I can help you</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Write a sentence about sports where every word starts with an S.</td>\n      <td>Sports such as soccer, swimming, squash, and skiing are a great way to stay physically fit and socially engaged. Sprinting, soccer, and snowboarding are excellent examples of sophisticated sports that require skill and strategic thinking. Sports enthusiasts should</td>\n      <td>Sure, I'd be happy to help! Sports enthusiasts often enjoy playing soccer, swimming, skiing, squash, and other sports that start with the letter S. Each activity offers unique challenges and benefits, such as improving stamina, strength, and strategic thinking. Whether</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Extract the facts from the paragraph.\\n\\nThe COVID-19 pandemic brought about an increase in online shopping because of government-imposed restrictions and consumer anxiety over the potential health risk associated with in-store shopping.</td>\n      <td>* Fact 1: The COVID-19 pandemic led to an increase in online shopping due to government-imposed restrictions.* Fact 2: Consumers were anxious about the potential health risks associated with in-store shopping during the pandemic.* Fact 3:</td>\n      <td>The facts extracted from the paragraph are:1. The COVID-19 pandemic led to an increase in online shopping.2. The increase in online shopping was caused by government-imposed restrictions.3. Consumers were anxious about the potential health risks associated with in-</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>You are a hotel manager greeting a VIP guest. How would you make the guest feel welcome and ensure a comfortable stay?</td>\n      <td>\"Welcome to our hotel, esteemed guest! *curtsies* I am thrilled to have you staying with us, and I am dedicated to making sure you have a comfortable and memorable experience. *smiles warmly*Firstly, I will ensure that your room is prepared</td>\n      <td>Hello there! It's a pleasure to welcome you to our hotel as a valued VIP guest. My name is [Your Name], and I'll be your hotel manager during your stay. I want to make sure that you feel right at home and have an incredible experience here, so please let</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push the peft model to huggingface"
      ],
      "metadata": {
        "id": "Et-ODQJisx-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dpo_trained_model.push_to_hub('panchub/peft_model_dpo_trained')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-08T21:35:59.800192Z",
          "iopub.execute_input": "2024-04-08T21:35:59.800671Z",
          "iopub.status.idle": "2024-04-08T21:36:16.107661Z",
          "shell.execute_reply.started": "2024-04-08T21:35:59.800634Z",
          "shell.execute_reply": "2024-04-08T21:36:16.106366Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "d0c5cfb844034bf3bf3e30e3fb52c019"
          ]
        },
        "id": "7jums7Disx-p",
        "outputId": "53bd564c-6e25-4f75-cd69-6bb70789d3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:141: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "adapter_model.safetensors:   0%|          | 0.00/551M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c5cfb844034bf3bf3e30e3fb52c019"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 120,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/panchub/peft_model_dpo_trained/commit/b9691eadbdfd4f2ed6ec12b13226d3eae15009db', commit_message='Upload LlamaForCausalLM', commit_description='', oid='b9691eadbdfd4f2ed6ec12b13226d3eae15009db', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    }
  ]
}